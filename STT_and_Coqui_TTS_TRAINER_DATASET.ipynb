{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/purushottampanchal/temp/blob/main/STT_and_Coqui_TTS_TRAINER_DATASET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_HkOd4jwqIb"
      },
      "source": [
        "**Fine tune a VITS model with the Coqui TTS framework using audio samples of your choice.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RUb7_iJu1mb",
        "outputId": "d0d373b2-00a5-490b-80d1-4cf39d5e0652"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@title gd connect\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UO0B3tVbPAKc"
      },
      "source": [
        "Set dataset and trainer output directory (model states saved here, subdirectory of dataset). Set upload_dir and place all audio files (Wav, mp3) in upload directory which will be /content/drive/MyDrive/{upload_dir}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GqNvXLc9ltKb"
      },
      "outputs": [],
      "source": [
        "#@title variables\n",
        "dataset_name = \"training-new\" #@param {type:\"string\"}\n",
        "output_directory = \"traineroutput\" #@param {type:\"string\"}\n",
        "upload_dir = \"Uploads\" #@param {type:\"string\"}\n",
        "upload_dir = \"/content/drive/MyDrive/\" + upload_dir\n",
        "#!mkdir $upload_dir"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title YT-DLP for downloading audio from Youtube \n",
        "\n",
        "\n",
        "!pip install yt-dlp"
      ],
      "metadata": {
        "id": "JiMEoVm1Uu1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls $upload_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TODv6VWOYCgT",
        "outputId": "b7e3c292-9928-4352-c328-51be48f634a8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training_audio1.wav  training_audio2.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title download youtube audio in wav\n",
        "!yt-dlp -x --audio-format wav -o $upload_dir/training_audio1.wav https://www.youtube.com/watch?v=WQsG8_4JTmw\n"
      ],
      "metadata": {
        "id": "gCJLW6lDU8pu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!yt-dlp -x --audio-format wav -o $upload_dir/training_audio2.wav https://www.youtube.com/watch?v=TKmf3VKh-Sc\n"
      ],
      "metadata": {
        "id": "ECKpRcFCXYfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cleanup previous audio processing"
      ],
      "metadata": {
        "id": "k2iOHpvbaL9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/drive/MyDrive/$upload_dir/out\n",
        "!rm -rf /content/drive/MyDrive/$dataset_name/converted"
      ],
      "metadata": {
        "id": "R-PoyqhKaLFP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIvwEf9zydzN"
      },
      "source": [
        "Download and Build Rnnoise (https://github.com/xiph/rnnoise) and Requirements (Optional if not processing .wav files for a new dataset. Multiple passes of rnnoise over samples may degrade audio quality. You should also preview your output dataset before training to ensure that the processing has not degraded any of your samples.  Occasionally, it will denoise too much of the tail end of phrases)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HigwgxZxEXf",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install pyloudnorm\n",
        "!git clone https://github.com/xiph/rnnoise.git\n",
        "!sudo apt-get install curl autoconf automake libtool python-dev pkg-config sox ffmpeg\n",
        "%cd /content/rnnoise\n",
        "!sh autogen.sh\n",
        "!sh configure\n",
        "!make clean\n",
        "!make"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "achSZMoMNcCQ"
      },
      "source": [
        "Install Sox, Install OpenAI Whisper STT+Translation (https://github.com/openai/whisper)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDN_GAyvNbeG",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!sudo apt install sox\n",
        "!git clone https://github.com/openai/whisper.git\n",
        "!pip install git+https://github.com/openai/whisper.git \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWzQveIIy7QW"
      },
      "source": [
        "Install Coqui TTS (https://github.com/coqui-ai/TTS), espeak-ng phonemeizer (https://github.com/espeak-ng/espeak-ng), download Coqui TTS source and examples from GitHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyCWXW_2y_nx",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "%cd /content\n",
        "!sudo apt-get install espeak-ng\n",
        "!git clone https://github.com/coqui-ai/TTS.git\n",
        "!pip install TTS\n",
        "#!tts --list_models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuK3Veok3zin"
      },
      "source": [
        "Convert mp3 files in upload_dir to wav as 22050hz mono wav\n",
        "Place output wav files in directory named 'out'.\n",
        "Copy any uploaded .wav files to 'out' as 22050hz mono wav.\n",
        "\n",
        "Make directory 'splits'. Use sox to split wav files into 8 second segments, placed in 'splits'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b58_cakYtYKB"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "%cd $upload_dir\n",
        "!rm -rf $upload_dir/out\n",
        "!mkdir $upload_dir/out\n",
        "!find . -name '*.mp3' -exec bash -c 'for f; do ffmpeg -i \"$f\" -acodec pcm_s16le -ar 22050 -ac 1 out/\"${f%.mp3}\".wav ; done' _ {} +\n",
        "!find . -name '*.wav' -exec bash -c 'for f; do ffmpeg -i \"$f\" -acodec pcm_s16le -ar 22050 -ac 1 out/\"${f%.wav}\".wav ; done' _ {} +\n",
        "\n",
        "\n",
        "!ls -al $upload_dir/out\n",
        "!mkdir $upload_dir/out/splits\n",
        "%cd $upload_dir/out\n",
        "!for FILE in *.wav; do sox \"$FILE\" splits/\"$FILE\" --show-progress silence 1 0.5 0.1% 1 0.5 0.1% : newfile : restart ; done\n",
        "#alt split method: force splits of 8 seconds, however this will split words. Comment the above with # and remove the # below to change\n",
        "#!for FILE in *.wav; do sox \"$FILE\" splits/\"$FILE\" --show-progress trim 0 8 : restart ; done\n",
        "%cd $upload_dir/out/splits\n",
        "!find . -name \"*.wav\" -type f -size -15k -delete"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIoB1kJFVbvm"
      },
      "source": [
        "(Optional) Run rnnoise, processed clips will be saved to your Google Drive in a folder named 'converted'. Files converted to 22khz mono for VITS model fine tuning.\n",
        "\n",
        "Original author unknown, but thank you for posting this helpful code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nzfmkv0aWN-7"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "orig_wavs= upload_dir + \"/out/splits\"\n",
        "from pathlib import Path\n",
        "import os\n",
        "import subprocess\n",
        "import soundfile as sf\n",
        "import pyloudnorm as pyln\n",
        "import sys\n",
        "import glob\n",
        "rnn = \"/content/rnnoise/examples/rnnoise_demo\"\n",
        "paths = glob.glob(os.path.join(orig_wavs, '*.wav'))\n",
        "for filepath in paths:\n",
        "  base = os.path.basename(filepath)\n",
        "  tp_s = \"/content/drive/MyDrive/\" + dataset_name + \"/\" + \"converted\" + \"/\"\n",
        "  tf_s = \"/content/drive/MyDrive/\" + dataset_name + \"/\" + \"converted\" + \"/\" + base\n",
        "  target_path = Path(tp_s)\n",
        "  target_file = Path(tf_s)\n",
        "  print(\"From: \" + str(filepath))\n",
        "  print(\"To: \" + str(target_file))\n",
        "\t\n",
        "# Stereo to Mono; upsample to 48000Hz\n",
        "# added -G to fix gain, -v 0.95\n",
        "  subprocess.run([\"sox\", \"-G\", \"-v\", \"0.95\", filepath, \"48k.wav\", \"remix\", \"-\", \"rate\", \"48000\"])\n",
        "  subprocess.run([\"sox\", \"48k.wav\", \"-c\", \"1\", \"-r\", \"48000\", \"-b\", \"16\", \"-e\", \"signed-integer\", \"-t\", \"raw\", \"temp.raw\"]) # convert wav to raw\n",
        "  subprocess.run([\"/content/rnnoise/examples/rnnoise_demo\", \"temp.raw\", \"rnn.raw\"]) # apply rnnoise\n",
        "  subprocess.run([\"sox\", \"-G\", \"-v\", \"0.95\", \"-r\", \"48k\", \"-b\", \"16\", \"-e\", \"signed-integer\", \"rnn.raw\", \"-t\", \"wav\", \"rnn.wav\"]) # convert raw back to wav\n",
        "\n",
        "  subprocess.run([\"mkdir\", \"-p\", str(target_path)])\n",
        "  subprocess.run([\"sox\", \"rnn.wav\", str(target_file), \"remix\", \"-\", \"highpass\", \"100\", \"lowpass\", \"7000\", \"rate\", \"22050\"]) # apply high/low pass filter and change sr to 22050Hz\n",
        "  data, rate = sf.read(target_file)\n",
        "\n",
        "# peak normalize audio to -1 dB\n",
        "  peak_normalized_audio = pyln.normalize.peak(data, -1.0)\n",
        "\n",
        "# measure the loudness first\n",
        "  meter = pyln.Meter(rate) # create BS.1770 meter\n",
        "  loudness = meter.integrated_loudness(data)\n",
        "\n",
        "# loudness normalize audio to -25 dB LUFS\n",
        "  loudness_normalized_audio = pyln.normalize.loudness(data, loudness, -25.0)\n",
        "  sf.write(target_file, data=loudness_normalized_audio, samplerate=22050)\n",
        "  print(\"\")\n",
        "%cd /content/drive/MyDrive/\"$dataset_name\"/converted/\n",
        "!find . -name \"*.wav\" -type f -size -15k -delete\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGAeXxPa1vnF",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#@title Copy wav files to dataset wav directory\n",
        "!mkdir /content/drive/MyDrive/$dataset_name/wavs\n",
        "!cp /content/drive/MyDrive/$dataset_name/converted/*.wav /content/drive/MyDrive/$dataset_name/wavs\n",
        "!ls -al /content/drive/MyDrive/$dataset_name/wavs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPp7FX6viuQe"
      },
      "outputs": [],
      "source": [
        "#@title Run Whisper on generated audio clips, generate transcript named metadata.csv in LJSpeech format in the dataset directory.\n",
        "import whisper\n",
        "import os, os.path\n",
        "import glob\n",
        "import pandas as pd\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "wavs = '/content/drive/MyDrive/'+dataset_name+'/wavs'\n",
        "\n",
        "model = whisper.load_model(\"medium.en\")\n",
        "paths = glob.glob(os.path.join(wavs, '*.wav'))\n",
        "print(len(paths))\n",
        "\n",
        "all_filenames = []\n",
        "transcript_text = []\n",
        "with open('/content/drive/MyDrive/'+dataset_name+'/metadata.csv', 'w', encoding='utf-8') as outfile:\n",
        "\tfor filepath in paths:\n",
        "\t\tbase = os.path.basename(filepath)\n",
        "\t\tall_filenames.append(base)\n",
        "\tfor filepath in paths:\n",
        "\t\tresult = model.transcribe(filepath)\n",
        "\t\toutput = result[\"text\"].lstrip()\n",
        "\t\toutput = output.replace(\"\\n\",\"\")\n",
        "\t\tthefile = str(os.path.basename(filepath).lstrip(\".\")).rsplit(\".\")[0]\n",
        "\t\toutfile.write(thefile + '|' + output + '|' + output + '\\n')\n",
        "\t\tprint(thefile + '|' + output + '|' + output + '\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIVhvXY4jb1m",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#@title Display dataset\n",
        "!cat /content/drive/MyDrive/$dataset_name/metadata.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EX5ftK4TzPUD"
      },
      "source": [
        "Download VITS model and Generate Sample Wav File to /content/ljspeech-vits.wav  This will be deleted when your Colab session is closed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vy-BadvazVNM",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!tts --text \"I am the very model of a modern Major General\" --model_name \"tts_models/en/ljspeech/vits\" --out_path /content/ljspeech-vits.wav"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Hkv4z1YcOfL"
      },
      "source": [
        "Save the training script with your dataset name, and output dir set. File will be saved in your Google drive dataset folder as train_vits.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "vTTt1CacqmF8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd41b180-342d-4888-827a-2971e7c42a3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw------- 1 root root 2995 May  5 06:16 /content/drive/MyDrive/training-new/train_vits.py\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "code = \"\"\"import os\n",
        "\n",
        "from trainer import Trainer, TrainerArgs\n",
        "\n",
        "from TTS.tts.configs.shared_configs import BaseDatasetConfig\n",
        "from TTS.tts.configs.vits_config import VitsConfig\n",
        "from TTS.tts.datasets import load_tts_samples\n",
        "from TTS.tts.models.vits import Vits, VitsAudioConfig\n",
        "from TTS.tts.utils.text.tokenizer import TTSTokenizer\n",
        "from TTS.utils.audio import AudioProcessor\n",
        "\n",
        "#output_path = os.path.dirname(os.path.abspath(__file__))\n",
        "##########################################\n",
        "#Change this to your dataset directory\n",
        "##########################################\n",
        "output_path = \"/content/drive/MyDrive/\"\"\"\n",
        "code = code + dataset_name + \"/\" + output_directory + \"/\" + \"\\\"\"\n",
        "\n",
        "code=code + \"\"\"\n",
        "dataset_config = BaseDatasetConfig(\n",
        "##########################################\n",
        "#Change this to your dataset directory\n",
        "##########################################\n",
        "    formatter=\"ljspeech\", meta_file_train=\"metadata.csv\", path=os.path.join(output_path, \"/content/drive/MyDrive/\"\"\"\n",
        "code = code + dataset_name\n",
        "code=code + \"\"\"\")\n",
        "\n",
        ")\n",
        "audio_config = VitsAudioConfig(\n",
        "    sample_rate=22050, win_length=1024, hop_length=256, num_mels=80, mel_fmin=0, mel_fmax=None\n",
        ")\n",
        "\n",
        "config = VitsConfig(\n",
        "    audio=audio_config,\n",
        "    run_name=\"vits_ljspeech\",\n",
        "    batch_size=8,\n",
        "    eval_batch_size=8,\n",
        "    batch_group_size=4,\n",
        "#    num_loader_workers=8,\n",
        "    num_loader_workers=4,\n",
        "    num_eval_loader_workers=4,\n",
        "    run_eval=True,\n",
        "    test_delay_epochs=-1,\n",
        "    epochs=100000,\n",
        "    save_step=1000,\n",
        "\t  save_checkpoints=True,\n",
        "\t  save_n_checkpoints=3,\n",
        "\t  save_best_after=1000,\n",
        "    #text_cleaner=\"english_cleaners\",\n",
        "    text_cleaner=\"multilingual_cleaners\",\n",
        "    use_phonemes=True,\n",
        "    phoneme_language=\"en-us\",\n",
        "    phoneme_cache_path=os.path.join(output_path, \"phoneme_cache\"),\n",
        "    compute_input_seq_cache=True,\n",
        "    print_step=25,\n",
        "    print_eval=True,\n",
        "    mixed_precision=True,\n",
        "    output_path=output_path,\n",
        "    datasets=[dataset_config],\n",
        "    cudnn_benchmark=False,\n",
        ")\n",
        "\n",
        "# INITIALIZE THE AUDIO PROCESSOR\n",
        "# Audio processor is used for feature extraction and audio I/O.\n",
        "# It mainly serves to the dataloader and the training loggers.\n",
        "ap = AudioProcessor.init_from_config(config)\n",
        "\n",
        "# INITIALIZE THE TOKENIZER\n",
        "# Tokenizer is used to convert text to sequences of token IDs.\n",
        "# config is updated with the default characters if not defined in the config.\n",
        "tokenizer, config = TTSTokenizer.init_from_config(config)\n",
        "\n",
        "# LOAD DATA SAMPLES\n",
        "# Each sample is a list of ```[text, audio_file_path, speaker_name]```\n",
        "# You can define your custom sample loader returning the list of samples.\n",
        "# Or define your custom formatter and pass it to the `load_tts_samples`.\n",
        "# Check `TTS.tts.datasets.load_tts_samples` for more details.\n",
        "train_samples, eval_samples = load_tts_samples(\n",
        "    dataset_config,\n",
        "    eval_split=True,\n",
        "    eval_split_max_size=config.eval_split_max_size,\n",
        "    eval_split_size=config.eval_split_size,\n",
        ")\n",
        "\n",
        "# init model\n",
        "model = Vits(config, ap, tokenizer, speaker_manager=None)\n",
        "\n",
        "# init the trainer and begin\n",
        "trainer = Trainer(\n",
        "    TrainerArgs(),\n",
        "    config,\n",
        "    output_path,\n",
        "    model=model,\n",
        "    train_samples=train_samples,\n",
        "    eval_samples=eval_samples,\n",
        ")\n",
        "trainer.fit()\n",
        "\"\"\"\n",
        "#print(code)\n",
        "myFile = open(\"/content/drive/MyDrive/\" + dataset_name + \"/train_vits.py\", 'w')\n",
        "\n",
        "myFile.write(code)\n",
        "myFile.close()\n",
        "%ls -al /content/drive/MyDrive/$dataset_name/train_vits.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XS08OyEVzeJA"
      },
      "source": [
        "Fine Tune VITS model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DviNKw7rzkyK"
      },
      "outputs": [],
      "source": [
        "!CUDA_VISIBLE_DEVICES=\"0\" python /content/drive/MyDrive/$dataset_name/train_vits.py --restore_path /root/.local/share/tts/tts_models--en--ljspeech--vits/model_file.pth --config_file /root/.local/share/tts/tts_models--en--ljspeech--vits/config.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3ydXqTyj-IH"
      },
      "source": [
        "**Resume a fine tuning session**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQYhcr_we74L"
      },
      "source": [
        "Run the next cell to list all of the saved run direcories.  Copy select the run you want to resume, ctrl+C to copy the name. Paste in the next cell and run it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vzxhbrTV8aw",
        "outputId": "5450a816-a947-49f5-d02e-141943e7b5ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "phoneme_cache\n",
            "vits_ljspeech-May-05-2023_06+22AM-0000000\n",
            "vits_ljspeech-May-05-2023_06+33AM-0000000\n",
            "vits_ljspeech-May-05-2023_08+39AM-0000000\n",
            "vits_ljspeech-May-05-2023_10+42AM-0000000\n",
            "vits_ljspeech-May-05-2023_10+51AM-0000000\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive/MyDrive/$dataset_name/$output_directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "g0mC-appmrRk"
      },
      "outputs": [],
      "source": [
        "run_name = \"vits_ljspeech-May-05-2023_06+33AM-0000000\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2YVQGVrfM67"
      },
      "source": [
        "Run this cell to list all of the checkpoints in the saved run, then put the checkpoint name in the next cell, and run it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xa2YtWfHZ4Xj",
        "outputId": "5b65ed23-ec8a-4ebe-d2fe-70b566299e20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_model_1003474.pth\tconfig.json\n",
            "best_model.pth\t\tevents.out.tfevents.1683268381.8f816e09b6f9\n",
            "checkpoint_1002000.pth\ttrainer_0_log.txt\n",
            "checkpoint_1003000.pth\ttrain_vits.py\n",
            "checkpoint_1004000.pth\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive/MyDrive/$dataset_name/$output_directory/$run_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "1Z59OjTpZ4ha"
      },
      "outputs": [],
      "source": [
        "model_checkpoint = \"best_model_1003474.pth\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2WQUoLhfrUu"
      },
      "source": [
        "Run the next cell to restore a previous fine tuning session using your dataset name, trainer output directory, and model checkpoint set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiM4XGXgnnIc"
      },
      "outputs": [],
      "source": [
        "!CUDA_VISIBLE_DEVICES=\"0\" python /content/drive/MyDrive/$dataset_name/train_vits.py --restore_path /content/drive/MyDrive/$dataset_name/$output_directory/$run_name/$model_checkpoint --config_path /content/drive/MyDrive/$dataset_name/$run_name/config.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZ2WoSCqzqxH"
      },
      "source": [
        "View Memory Usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ryma4sViztPk"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMqzKCacnPvX"
      },
      "outputs": [],
      "source": [
        "#@title Load Tensorboard\n",
        "import torch \n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/$dataset_name/$output_directory/"
      ],
      "metadata": {
        "id": "taoIFU2E2BCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kill 1349"
      ],
      "metadata": {
        "id": "fUrQv_3DB5Xt"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxPBHCGf0AVt"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir /content/drive/MyDrive/$dataset_name/$output_directory/ --port 8008"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}